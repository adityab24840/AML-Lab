{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Demo: Random Forest Feature Importance for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n",
      "**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \n",
      "**Please cite**:  \n",
      "\n",
      "The MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n",
      "\n",
      "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n",
      "\n",
      "With some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n",
      "\n",
      "The MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "print(mnist.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0  \n",
       "4       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mnist.data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel782  pixel783  pixel784  label  \n",
       "0       0.0       0.0       0.0      5  \n",
       "1       0.0       0.0       0.0      0  \n",
       "2       0.0       0.0       0.0      4  \n",
       "3       0.0       0.0       0.0      1  \n",
       "4       0.0       0.0       0.0      9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine label into dataframe\n",
    "df['label'] = mnist.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at features and labels separately\n",
    "X = df.iloc[:,0:-1:]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "69995       0.0       0.0       0.0       0.0       0.0  \n",
       "69996       0.0       0.0       0.0       0.0       0.0  \n",
       "69997       0.0       0.0       0.0       0.0       0.0  \n",
       "69998       0.0       0.0       0.0       0.0       0.0  \n",
       "69999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X.iloc[0].values.reshape(28,28)\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(X.iloc[0].values.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.12910351e-07, 1.65876346e-06,\n",
       "       1.21943967e-06, 7.93422144e-07, 9.42478294e-07, 4.71862001e-06,\n",
       "       3.25300581e-06, 2.72519750e-06, 2.94067112e-06, 2.68351374e-06,\n",
       "       7.42350268e-06, 1.54003460e-06, 1.09351300e-06, 4.73802742e-07,\n",
       "       5.48880511e-07, 6.88048663e-07, 2.91083159e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.43272308e-06, 8.82802402e-06,\n",
       "       1.89995068e-05, 3.10721208e-05, 6.27394872e-05, 1.17164633e-04,\n",
       "       1.54645637e-04, 2.39317292e-04, 8.69569700e-05, 2.59852941e-04,\n",
       "       7.82159185e-05, 1.41680815e-04, 3.56607818e-05, 2.25805713e-05,\n",
       "       1.22300481e-05, 1.49032782e-05, 4.98814156e-06, 4.18821552e-06,\n",
       "       1.58804070e-07, 1.57459374e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.76353297e-07,\n",
       "       0.00000000e+00, 2.98360201e-06, 7.22077975e-06, 3.64316595e-05,\n",
       "       4.78485893e-05, 1.42342008e-04, 2.96092922e-04, 5.63752135e-04,\n",
       "       9.40956703e-04, 6.27766482e-04, 1.45245340e-03, 1.91016238e-03,\n",
       "       2.14012437e-03, 2.14419346e-03, 1.25855740e-03, 1.00575816e-03,\n",
       "       4.64356815e-04, 2.10594636e-04, 5.18841398e-05, 2.08037702e-05,\n",
       "       1.00447443e-05, 1.94675687e-06, 3.02103020e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.94307813e-07,\n",
       "       1.72514457e-06, 7.68720818e-06, 3.97252441e-05, 5.86308136e-05,\n",
       "       1.80183216e-04, 3.12818651e-04, 7.60340490e-04, 1.18298349e-03,\n",
       "       1.24110402e-03, 1.94954030e-03, 2.83694502e-03, 1.70089132e-03,\n",
       "       1.76501857e-03, 1.13185354e-03, 9.77995328e-04, 7.24686616e-04,\n",
       "       4.65593993e-04, 2.18222304e-04, 1.35056141e-04, 8.77355031e-05,\n",
       "       4.24712042e-05, 1.93046253e-05, 1.56346232e-06, 9.35581694e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.36063544e-06,\n",
       "       1.14616078e-05, 4.12036749e-05, 1.27253948e-04, 2.53454214e-04,\n",
       "       6.30521035e-04, 1.41661383e-03, 2.25986406e-03, 2.78217145e-03,\n",
       "       2.90822748e-03, 4.90495186e-03, 6.19912383e-03, 5.56486565e-03,\n",
       "       4.76542421e-03, 2.87166052e-03, 2.63340290e-03, 1.42657918e-03,\n",
       "       7.57524187e-04, 7.78285175e-04, 6.46613193e-04, 4.39799414e-04,\n",
       "       1.21774721e-04, 2.64474010e-05, 1.10523389e-05, 3.16724624e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.10093811e-07, 7.16866334e-06,\n",
       "       3.20921511e-05, 1.16885008e-04, 2.12705335e-04, 4.62704053e-04,\n",
       "       1.32154473e-03, 1.90281136e-03, 2.32033794e-03, 3.05765463e-03,\n",
       "       3.06191145e-03, 2.13395898e-03, 3.72915169e-03, 4.37178362e-03,\n",
       "       2.71994565e-03, 2.75163044e-03, 1.92879283e-03, 1.51055194e-03,\n",
       "       1.46548047e-03, 1.13513062e-03, 1.14758237e-03, 9.74443978e-04,\n",
       "       2.54772070e-04, 7.29127816e-05, 1.31489030e-05, 1.21896186e-06,\n",
       "       0.00000000e+00, 7.95196136e-07, 1.70917280e-06, 1.40732371e-05,\n",
       "       7.74659200e-05, 1.41954596e-04, 3.08022622e-04, 6.25894915e-04,\n",
       "       1.37747695e-03, 1.32018140e-03, 2.16746930e-03, 2.06903922e-03,\n",
       "       2.14086244e-03, 4.03706484e-03, 5.48629925e-03, 6.93498296e-03,\n",
       "       6.09633208e-03, 3.08210558e-03, 1.85313474e-03, 2.41553889e-03,\n",
       "       1.75082687e-03, 1.48968465e-03, 1.62402053e-03, 1.00148042e-03,\n",
       "       1.12138291e-03, 1.08518843e-04, 1.57432296e-05, 4.27816781e-06,\n",
       "       0.00000000e+00, 3.15543917e-07, 5.86286467e-06, 1.69845624e-05,\n",
       "       8.58369614e-05, 1.78473814e-04, 4.19018537e-04, 8.76647205e-04,\n",
       "       1.07651931e-03, 1.50456690e-03, 1.87257657e-03, 4.74254284e-03,\n",
       "       2.99448092e-03, 4.23637723e-03, 4.54913660e-03, 5.07048279e-03,\n",
       "       3.93975435e-03, 3.30803818e-03, 3.58615412e-03, 2.68856283e-03,\n",
       "       2.59918417e-03, 1.53213770e-03, 1.15969635e-03, 1.41501991e-03,\n",
       "       6.92669388e-04, 1.06328525e-04, 2.27708553e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.79450999e-06, 3.58614553e-06, 3.92025056e-05,\n",
       "       1.05656100e-04, 2.16817091e-04, 3.35851612e-04, 7.56457161e-04,\n",
       "       1.31241923e-03, 1.96525751e-03, 4.43393054e-03, 5.00261182e-03,\n",
       "       3.59296771e-03, 2.94089809e-03, 3.87188638e-03, 3.54540274e-03,\n",
       "       3.00752267e-03, 3.59332155e-03, 4.12599944e-03, 3.37006393e-03,\n",
       "       2.60732227e-03, 1.47797034e-03, 1.20269962e-03, 7.41403565e-04,\n",
       "       5.57975987e-04, 1.24373931e-04, 2.03859504e-05, 1.24824920e-06,\n",
       "       1.58772941e-07, 2.11705666e-07, 6.18252180e-06, 3.35799934e-05,\n",
       "       9.40520764e-05, 2.46248499e-04, 4.11310582e-04, 8.59625082e-04,\n",
       "       1.86215451e-03, 3.25021805e-03, 4.90595901e-03, 4.79480652e-03,\n",
       "       3.45176158e-03, 2.66878594e-03, 2.89092444e-03, 4.24782496e-03,\n",
       "       4.05450620e-03, 3.82702753e-03, 3.94113483e-03, 2.66988901e-03,\n",
       "       2.78140626e-03, 2.11633876e-03, 1.06043065e-03, 4.61694532e-04,\n",
       "       2.61090647e-04, 5.57203717e-05, 1.36267550e-05, 2.98581618e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.74824799e-06, 2.42800653e-05,\n",
       "       6.33772718e-05, 2.16788191e-04, 5.95682411e-04, 1.33857808e-03,\n",
       "       1.85828296e-03, 4.00382159e-03, 5.11628507e-03, 5.00168730e-03,\n",
       "       3.73244921e-03, 3.06784972e-03, 3.87030069e-03, 4.41470871e-03,\n",
       "       3.89615118e-03, 3.57483650e-03, 4.71061680e-03, 3.24443987e-03,\n",
       "       2.20413727e-03, 1.65759281e-03, 1.12122468e-03, 3.91378555e-04,\n",
       "       1.15115109e-04, 3.13274123e-05, 7.34809509e-06, 6.23391142e-07,\n",
       "       0.00000000e+00, 5.85268007e-07, 1.82160520e-06, 1.84251679e-05,\n",
       "       9.49977228e-05, 2.76844478e-04, 8.03072803e-04, 1.47756974e-03,\n",
       "       2.39754110e-03, 5.93243000e-03, 5.60823595e-03, 6.25097569e-03,\n",
       "       4.27698787e-03, 3.85136920e-03, 8.83931923e-03, 4.00276454e-03,\n",
       "       3.34253820e-03, 3.88548783e-03, 4.37502122e-03, 2.74754999e-03,\n",
       "       1.76102679e-03, 1.35307756e-03, 2.79346183e-03, 6.35371612e-04,\n",
       "       1.31005079e-04, 2.00258885e-05, 6.52697620e-06, 8.79899274e-07,\n",
       "       0.00000000e+00, 1.19463541e-06, 2.24471696e-06, 2.36547602e-05,\n",
       "       8.55678172e-05, 5.13285121e-04, 1.15569979e-03, 1.82681063e-03,\n",
       "       3.20014220e-03, 4.83519440e-03, 5.90030337e-03, 6.00349436e-03,\n",
       "       5.75980192e-03, 8.27389943e-03, 7.52926914e-03, 5.22815407e-03,\n",
       "       4.06198455e-03, 5.76046650e-03, 4.29280046e-03, 1.66642408e-03,\n",
       "       1.23095824e-03, 1.39749158e-03, 4.11225191e-03, 4.61416368e-04,\n",
       "       1.52342417e-04, 2.48813006e-05, 6.51088466e-06, 1.37024807e-06,\n",
       "       0.00000000e+00, 1.58777996e-07, 5.43638107e-07, 1.86081889e-05,\n",
       "       8.11009332e-05, 4.46663001e-04, 9.40724397e-04, 1.74011014e-03,\n",
       "       3.70898260e-03, 4.74636185e-03, 4.35535677e-03, 4.86077423e-03,\n",
       "       4.26116341e-03, 7.51758158e-03, 7.19508561e-03, 5.14968937e-03,\n",
       "       4.54637577e-03, 5.41601022e-03, 3.20139799e-03, 1.65612446e-03,\n",
       "       1.54934638e-03, 1.87868902e-03, 1.73364422e-03, 9.60961093e-04,\n",
       "       1.54307886e-04, 3.22403843e-05, 5.39045677e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.89520859e-06, 1.90603307e-05,\n",
       "       8.73706130e-05, 5.09734988e-04, 1.17759584e-03, 3.81926134e-03,\n",
       "       3.50225903e-03, 5.68095235e-03, 5.28081111e-03, 6.19156675e-03,\n",
       "       4.67320045e-03, 7.40468566e-03, 6.89236026e-03, 5.01914689e-03,\n",
       "       4.33677316e-03, 6.24004611e-03, 3.68114151e-03, 1.46718227e-03,\n",
       "       1.18715570e-03, 1.68727782e-03, 8.34844184e-04, 5.36600600e-04,\n",
       "       1.55534463e-04, 4.17863768e-05, 1.23768385e-05, 1.06084666e-06,\n",
       "       0.00000000e+00, 4.41059701e-07, 3.56235130e-06, 3.01848287e-05,\n",
       "       9.35271115e-05, 4.15401331e-04, 1.39938002e-03, 3.04551473e-03,\n",
       "       3.52366596e-03, 4.01923541e-03, 4.53916898e-03, 4.45247664e-03,\n",
       "       5.03600096e-03, 7.16510742e-03, 5.02503279e-03, 4.28920496e-03,\n",
       "       3.31635563e-03, 3.90205235e-03, 2.37094913e-03, 1.19788845e-03,\n",
       "       1.47434907e-03, 1.29051474e-03, 7.01936166e-04, 4.01249635e-04,\n",
       "       1.70778119e-04, 7.36010677e-05, 1.84796677e-05, 1.93103564e-06,\n",
       "       0.00000000e+00, 4.65755331e-07, 4.56891659e-06, 2.95612796e-05,\n",
       "       1.10866566e-04, 4.84204711e-04, 1.30617746e-03, 2.38692746e-03,\n",
       "       3.39947110e-03, 4.39274037e-03, 4.55208197e-03, 5.84426630e-03,\n",
       "       5.59727149e-03, 6.03964162e-03, 3.61487076e-03, 2.70976536e-03,\n",
       "       1.84677291e-03, 2.04175158e-03, 2.49778410e-03, 1.64564236e-03,\n",
       "       1.59558306e-03, 8.59310045e-04, 5.13548776e-04, 2.94829648e-04,\n",
       "       2.35178447e-04, 5.71705894e-05, 1.28141070e-05, 3.47028185e-06,\n",
       "       6.01250411e-07, 0.00000000e+00, 6.44461573e-06, 5.73066822e-05,\n",
       "       2.01263081e-04, 5.11243793e-04, 1.49882009e-03, 2.62831352e-03,\n",
       "       2.45560081e-03, 4.47348292e-03, 5.92253593e-03, 6.21153695e-03,\n",
       "       4.45929341e-03, 4.43765994e-03, 2.59628223e-03, 1.80878824e-03,\n",
       "       1.45656369e-03, 2.02490822e-03, 2.20944981e-03, 2.29886493e-03,\n",
       "       1.87330103e-03, 9.65076698e-04, 5.94126619e-04, 3.87547957e-04,\n",
       "       2.08133416e-04, 3.66431058e-05, 5.56998775e-06, 1.14435747e-06,\n",
       "       0.00000000e+00, 4.63109623e-07, 6.25223734e-06, 7.24115666e-05,\n",
       "       1.91053463e-04, 5.34578858e-04, 2.21825310e-03, 2.39288146e-03,\n",
       "       3.68211690e-03, 4.58855398e-03, 5.70998480e-03, 5.76521014e-03,\n",
       "       3.71456504e-03, 2.81902031e-03, 1.81861406e-03, 1.32241604e-03,\n",
       "       1.15035405e-03, 2.65447790e-03, 3.23661696e-03, 1.48469608e-03,\n",
       "       1.18184857e-03, 9.54710531e-04, 7.84271776e-04, 4.06182499e-04,\n",
       "       2.14496052e-04, 4.42835911e-05, 7.50950719e-06, 3.06661451e-07,\n",
       "       0.00000000e+00, 8.91149128e-07, 7.34870898e-06, 5.30060079e-05,\n",
       "       2.94133138e-04, 5.81484535e-04, 1.81640183e-03, 3.25020548e-03,\n",
       "       4.00415615e-03, 6.15893656e-03, 5.78659254e-03, 3.78361810e-03,\n",
       "       3.17615130e-03, 2.39366040e-03, 1.62742675e-03, 1.64119821e-03,\n",
       "       1.91068181e-03, 1.92596455e-03, 3.48050570e-03, 2.21664257e-03,\n",
       "       1.32380412e-03, 1.06364455e-03, 5.23534644e-04, 3.01376834e-04,\n",
       "       9.02714974e-05, 2.68366238e-05, 1.76959146e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.42056796e-06, 8.12186419e-05,\n",
       "       1.46668636e-04, 3.95814604e-04, 1.11406087e-03, 2.89981453e-03,\n",
       "       5.82142019e-03, 3.26252591e-03, 2.20826680e-03, 1.82761079e-03,\n",
       "       1.56767716e-03, 1.39521385e-03, 1.25821208e-03, 1.17468953e-03,\n",
       "       1.19190419e-03, 1.47267744e-03, 9.92672980e-04, 1.25253130e-03,\n",
       "       1.11914463e-03, 5.22407189e-04, 3.29581057e-04, 1.72141571e-04,\n",
       "       5.40047446e-05, 1.13293518e-05, 1.27878157e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 5.19441515e-07, 3.37853342e-06, 2.09604268e-05,\n",
       "       8.06587461e-05, 2.49573132e-04, 5.90021427e-04, 1.50635084e-03,\n",
       "       2.94986732e-03, 2.79719545e-03, 2.69584917e-03, 2.81932200e-03,\n",
       "       1.78532340e-03, 1.97748146e-03, 1.54302674e-03, 1.45286858e-03,\n",
       "       1.22638191e-03, 1.11761742e-03, 8.00469130e-04, 6.54566048e-04,\n",
       "       4.20743639e-04, 2.33280307e-04, 2.05375951e-04, 7.19649089e-05,\n",
       "       2.16332917e-05, 5.12087036e-06, 2.72436381e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.54626669e-07, 2.03503845e-05,\n",
       "       5.87803189e-05, 1.14438380e-04, 2.61199346e-04, 6.38801745e-04,\n",
       "       1.10765512e-03, 2.70320291e-03, 4.12310083e-03, 4.33112499e-03,\n",
       "       4.70736318e-03, 5.74517678e-03, 3.56640028e-03, 2.88361356e-03,\n",
       "       1.62432139e-03, 1.20563016e-03, 7.63476980e-04, 4.31829043e-04,\n",
       "       1.97511610e-04, 1.36301700e-04, 5.79397147e-05, 2.56839972e-05,\n",
       "       1.37268178e-05, 8.82670422e-07, 2.96387010e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.19257426e-06, 9.69642268e-06,\n",
       "       3.71306462e-05, 1.00062798e-04, 2.74689971e-04, 3.91048122e-04,\n",
       "       6.09314347e-04, 8.65768337e-04, 9.51889147e-04, 1.58802561e-03,\n",
       "       1.10185454e-03, 1.51132028e-03, 9.24810104e-04, 7.33530120e-04,\n",
       "       5.10994744e-04, 4.04543629e-04, 5.34897786e-04, 2.50156096e-04,\n",
       "       1.37708944e-04, 1.00692320e-04, 4.41420709e-05, 1.94871865e-05,\n",
       "       2.43139712e-06, 1.81933072e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.53034920e-06,\n",
       "       1.57447505e-05, 4.80852841e-05, 1.51266590e-04, 2.58263083e-04,\n",
       "       4.45472073e-04, 7.84040677e-04, 8.93628836e-04, 9.49906262e-04,\n",
       "       1.54754270e-03, 7.49981007e-04, 5.91234539e-04, 7.02603267e-04,\n",
       "       4.15113787e-04, 4.18337719e-04, 3.66343222e-04, 1.63771207e-04,\n",
       "       1.18860627e-04, 5.76780907e-05, 1.50106841e-05, 7.50391425e-06,\n",
       "       1.77854476e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.70792078e-06, 6.57835373e-06, 1.11115106e-05, 3.83078544e-05,\n",
       "       8.57230712e-05, 8.84547700e-05, 2.15077747e-04, 3.21133819e-04,\n",
       "       3.00761772e-04, 2.12049106e-04, 3.97034536e-04, 1.21882847e-04,\n",
       "       1.58887111e-04, 1.17425774e-04, 7.21085998e-05, 6.00189346e-05,\n",
       "       1.99403725e-05, 8.38110527e-06, 1.01822463e-06, 7.23027472e-07,\n",
       "       5.19689043e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.96398373e-07, 0.00000000e+00,\n",
       "       5.54038446e-07, 1.88408001e-06, 1.29017664e-06, 2.40214236e-06,\n",
       "       2.89532437e-06, 5.99538496e-06, 3.02130725e-06, 3.25018925e-06,\n",
       "       2.67370488e-06, 2.52282846e-06, 2.45465085e-06, 5.17873800e-07,\n",
       "       1.35227340e-06, 1.48335567e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(rf.feature_importances_.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(rf.feature_importances_ > 0.004)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove constant/quasi-constant features\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n (x^{(i)}-\\bar{x})^2\n",
    "$$\n",
    "\n",
    "| F1 | F2 | F3 | F4 |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 0 | 1 | 2 |\n",
    "| 2 | 8 | 1 | 2 |\n",
    "| 4 | 5 | 1 | 2 |\n",
    "| 6 | 6 | 1 | 0 |\n",
    "| 9 | 4 | 1 | 2 |\n",
    "\n",
    "\n",
    "1. Features with zero or low variance do not explain the target variable in any way (i.e. no predictive power).\n",
    "2. Such features can be removed by using VarianceThreshold transformer\n",
    "3. It takes a threshold cut-off value. All values below that threshold value will be dropped\n",
    "4. Default threshold value = 0. It drops only constant\n",
    "5. A quasi-constant feature, using a threshold of 0.1 means 90% of the values are similar\n",
    "6. Although not mandatory, normalizing (not standardizing) the features before applying VarianceThreshold is a good idea for exploratory purposes of fairer comparison of variance across features and set a cutoff. Otherwise variance is a running value\n",
    "7. Can be applied for Categorical variables after Label/Ordinal Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**:\n",
    "Used below is a public dataset from 2012 U.S. Army Anthropometric Survey: http://mreed.umtri.umich.edu/mreed/downloads/anthro/ANSUR2Distribution.zip. The zip contains CSV for male and female. Only make dataset is used for testing VarianceThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demo\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = [['blue'], ['green'], ['blue'], ['blue'], \n",
    "     ['green'], ['red'], ['blue'], ['green']]\n",
    "y = [0, 0, 1, 0, 0, 1, 0, 0]\n",
    "\n",
    "enc = OneHotEncoder(drop='first')\n",
    "enc.fit(X)\n",
    "X_ohe = enc.transform(X)\n",
    "X_ohe.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "\n",
    "sel.fit(X_ohe)\n",
    "sel.transform(X_ohe).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On real dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectid</th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>...</th>\n",
       "      <th>Branch</th>\n",
       "      <th>PrimaryMOS</th>\n",
       "      <th>SubjectsBirthLocation</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "      <th>WritingPreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10027</td>\n",
       "      <td>266</td>\n",
       "      <td>1467</td>\n",
       "      <td>337</td>\n",
       "      <td>222</td>\n",
       "      <td>1347</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "      <td>401</td>\n",
       "      <td>369</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Arms</td>\n",
       "      <td>19D</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>180</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10032</td>\n",
       "      <td>233</td>\n",
       "      <td>1395</td>\n",
       "      <td>326</td>\n",
       "      <td>220</td>\n",
       "      <td>1293</td>\n",
       "      <td>245</td>\n",
       "      <td>193</td>\n",
       "      <td>394</td>\n",
       "      <td>338</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>160</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10033</td>\n",
       "      <td>287</td>\n",
       "      <td>1430</td>\n",
       "      <td>341</td>\n",
       "      <td>230</td>\n",
       "      <td>1327</td>\n",
       "      <td>256</td>\n",
       "      <td>196</td>\n",
       "      <td>427</td>\n",
       "      <td>408</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>205</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10092</td>\n",
       "      <td>234</td>\n",
       "      <td>1347</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>1239</td>\n",
       "      <td>262</td>\n",
       "      <td>199</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>88M</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>175</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10093</td>\n",
       "      <td>250</td>\n",
       "      <td>1585</td>\n",
       "      <td>372</td>\n",
       "      <td>247</td>\n",
       "      <td>1478</td>\n",
       "      <td>267</td>\n",
       "      <td>224</td>\n",
       "      <td>435</td>\n",
       "      <td>356</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>92G</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>213</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjectid  abdominalextensiondepthsitting  acromialheight  \\\n",
       "0      10027                             266            1467   \n",
       "1      10032                             233            1395   \n",
       "2      10033                             287            1430   \n",
       "3      10092                             234            1347   \n",
       "4      10093                             250            1585   \n",
       "\n",
       "   acromionradialelength  anklecircumference  axillaheight  \\\n",
       "0                    337                 222          1347   \n",
       "1                    326                 220          1293   \n",
       "2                    341                 230          1327   \n",
       "3                    310                 230          1239   \n",
       "4                    372                 247          1478   \n",
       "\n",
       "   balloffootcircumference  balloffootlength  biacromialbreadth  \\\n",
       "0                      253               202                401   \n",
       "1                      245               193                394   \n",
       "2                      256               196                427   \n",
       "3                      262               199                401   \n",
       "4                      267               224                435   \n",
       "\n",
       "   bicepscircumferenceflexed  ...                  Branch  PrimaryMOS  \\\n",
       "0                        369  ...             Combat Arms         19D   \n",
       "1                        338  ...          Combat Support         68W   \n",
       "2                        408  ...          Combat Support         68W   \n",
       "3                        359  ...  Combat Service Support         88M   \n",
       "4                        356  ...  Combat Service Support         92G   \n",
       "\n",
       "   SubjectsBirthLocation  SubjectNumericRace  Ethnicity  DODRace  Age  \\\n",
       "0           North Dakota                   1        NaN        1   41   \n",
       "1               New York                   1        NaN        1   35   \n",
       "2               New York                   2        NaN        2   42   \n",
       "3              Wisconsin                   1        NaN        1   31   \n",
       "4         North Carolina                   2        NaN        2   21   \n",
       "\n",
       "   Heightin  Weightlbs  WritingPreference  \n",
       "0        71        180         Right hand  \n",
       "1        68        160          Left hand  \n",
       "2        68        205          Left hand  \n",
       "3        66        175         Right hand  \n",
       "4        77        213         Right hand  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\MSIS\\Applied Machine Learning (AML)\\AML Lab\\Feature Selection\\ANSUR II MALE Public.csv\", encoding='latin')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>bicristalbreadth</th>\n",
       "      <th>...</th>\n",
       "      <th>Branch</th>\n",
       "      <th>PrimaryMOS</th>\n",
       "      <th>SubjectsBirthLocation</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "      <th>WritingPreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>266</td>\n",
       "      <td>1467</td>\n",
       "      <td>337</td>\n",
       "      <td>222</td>\n",
       "      <td>1347</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "      <td>401</td>\n",
       "      <td>369</td>\n",
       "      <td>274</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Arms</td>\n",
       "      <td>19D</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>180</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>1395</td>\n",
       "      <td>326</td>\n",
       "      <td>220</td>\n",
       "      <td>1293</td>\n",
       "      <td>245</td>\n",
       "      <td>193</td>\n",
       "      <td>394</td>\n",
       "      <td>338</td>\n",
       "      <td>257</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>160</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287</td>\n",
       "      <td>1430</td>\n",
       "      <td>341</td>\n",
       "      <td>230</td>\n",
       "      <td>1327</td>\n",
       "      <td>256</td>\n",
       "      <td>196</td>\n",
       "      <td>427</td>\n",
       "      <td>408</td>\n",
       "      <td>261</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>205</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234</td>\n",
       "      <td>1347</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>1239</td>\n",
       "      <td>262</td>\n",
       "      <td>199</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>262</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>88M</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>175</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>1585</td>\n",
       "      <td>372</td>\n",
       "      <td>247</td>\n",
       "      <td>1478</td>\n",
       "      <td>267</td>\n",
       "      <td>224</td>\n",
       "      <td>435</td>\n",
       "      <td>356</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>92G</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>213</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdominalextensiondepthsitting  acromialheight  acromionradialelength  \\\n",
       "0                             266            1467                    337   \n",
       "1                             233            1395                    326   \n",
       "2                             287            1430                    341   \n",
       "3                             234            1347                    310   \n",
       "4                             250            1585                    372   \n",
       "\n",
       "   anklecircumference  axillaheight  balloffootcircumference  \\\n",
       "0                 222          1347                      253   \n",
       "1                 220          1293                      245   \n",
       "2                 230          1327                      256   \n",
       "3                 230          1239                      262   \n",
       "4                 247          1478                      267   \n",
       "\n",
       "   balloffootlength  biacromialbreadth  bicepscircumferenceflexed  \\\n",
       "0               202                401                        369   \n",
       "1               193                394                        338   \n",
       "2               196                427                        408   \n",
       "3               199                401                        359   \n",
       "4               224                435                        356   \n",
       "\n",
       "   bicristalbreadth  ...                  Branch  PrimaryMOS  \\\n",
       "0               274  ...             Combat Arms         19D   \n",
       "1               257  ...          Combat Support         68W   \n",
       "2               261  ...          Combat Support         68W   \n",
       "3               262  ...  Combat Service Support         88M   \n",
       "4               263  ...  Combat Service Support         92G   \n",
       "\n",
       "   SubjectsBirthLocation  SubjectNumericRace  Ethnicity  DODRace  Age  \\\n",
       "0           North Dakota                   1        NaN        1   41   \n",
       "1               New York                   1        NaN        1   35   \n",
       "2               New York                   2        NaN        2   42   \n",
       "3              Wisconsin                   1        NaN        1   31   \n",
       "4         North Carolina                   2        NaN        2   21   \n",
       "\n",
       "   Heightin  Weightlbs  WritingPreference  \n",
       "0        71        180         Right hand  \n",
       "1        68        160          Left hand  \n",
       "2        68        205          Left hand  \n",
       "3        66        175         Right hand  \n",
       "4        77        213         Right hand  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"subjectid\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4082, 107)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # 107 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\MSIS\\Applied Machine Learning (AML)\\AML Lab\\Feature Selection\\ANSUR II MALE Public.csv\", encoding='latin')\n",
    "df.drop(columns=[\"subjectid\"], inplace=True)\n",
    "\n",
    "df = df.select_dtypes(include='number')\n",
    "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2857, 97)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Run with all features\n",
    "\n",
    "Note the accuracy and time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7 s ± 33.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9881479469826502\n",
      "Test Score: 0.9492110737733014\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train, y_train)\n",
    "print(f\"Training Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Identify quasi-constant features with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abdominalextensiondepthsitting     254.275814\n",
       "acromialheight                    1440.459573\n",
       "acromionradialelength              335.198110\n",
       "anklecircumference                 229.320266\n",
       "axillaheight                      1328.778089\n",
       "                                     ...     \n",
       "wristheight                        847.625481\n",
       "SubjectNumericRace                   8.388519\n",
       "DODRace                              1.513826\n",
       "Age                                 30.015401\n",
       "Heightin                            70.017501\n",
       "Length: 97, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean = X_train.mean()\n",
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train / x_mean\n",
    "X_test_normalized = X_test/x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abdominalextensiondepthsitting', 'acromialheight', 'acromionradialelength', 'anklecircumference', 'axillaheight', 'balloffootcircumference', 'balloffootlength', 'biacromialbreadth', 'bicepscircumferenceflexed', 'bicristalbreadth', 'bideltoidbreadth', 'bimalleolarbreadth', 'bitragionchinarc', 'bitragionsubmandibulararc', 'bizygomaticbreadth', 'buttockcircumference', 'buttockdepth', 'buttockheight', 'buttockkneelength', 'buttockpopliteallength', 'calfcircumference', 'cervicaleheight', 'chestbreadth', 'chestcircumference', 'chestdepth', 'chestheight', 'crotchheight', 'crotchlengthomphalion', 'crotchlengthposterioromphalion', 'earbreadth', 'earlength', 'earprotrusion', 'elbowrestheight', 'eyeheightsitting', 'footbreadthhorizontal', 'footlength', 'forearmcenterofgriplength', 'forearmcircumferenceflexed', 'forearmforearmbreadth', 'forearmhandlength', 'functionalleglength', 'handbreadth', 'handcircumference', 'handlength', 'headbreadth', 'headcircumference', 'headlength', 'heelanklecircumference', 'heelbreadth', 'hipbreadth', 'hipbreadthsitting', 'iliocristaleheight', 'interpupillarybreadth', 'interscyei', 'interscyeii', 'kneeheightmidpatella', 'kneeheightsitting', 'lateralfemoralepicondyleheight', 'lateralmalleolusheight', 'lowerthighcircumference', 'mentonsellionlength', 'neckcircumference', 'neckcircumferencebase', 'overheadfingertipreachsitting', 'palmlength', 'poplitealheight', 'radialestylionlength', 'shouldercircumference', 'shoulderelbowlength', 'shoulderlength', 'sittingheight', 'sleevelengthspinewrist', 'sleeveoutseam', 'span', 'stature', 'suprasternaleheight', 'tenthribheight', 'thighcircumference', 'thighclearance', 'thumbtipreach', 'tibialheight', 'tragiontopofhead', 'trochanterionheight', 'verticaltrunkcircumferenceusa', 'waistbacklength', 'waistbreadth', 'waistcircumference', 'waistdepth', 'waistfrontlengthsitting', 'waistheightomphalion', 'weightkg', 'wristcircumference', 'wristheight', 'Heightin']\n"
     ]
    }
   ],
   "source": [
    "quasi_constant_features = [feat for feat in X_train.columns if X_train_normalized[feat].var() <= 0.03]\n",
    "print(quasi_constant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3. Identify quasi-constant features with VarianceThreshold\n",
    "\n",
    "1. StandardScaler is not used because it sets variance = 1\n",
    "2. Normalizer is not used because the output of the transformer will no longer be a dataframe. We will do it from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#normalizer = Normalizer()\n",
    "#X_train_normalized = normalizer.fit_transform(X_train)\n",
    "#X_test_normalized = normalizer.transform(X_test)\n",
    "\n",
    "# Normalizer is not used because the output is no longer a dataframe.\n",
    "# We will do it frm scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abdominalextensiondepthsitting     254.275814\n",
       "acromialheight                    1440.459573\n",
       "acromionradialelength              335.198110\n",
       "anklecircumference                 229.320266\n",
       "axillaheight                      1328.778089\n",
       "                                     ...     \n",
       "wristheight                        847.625481\n",
       "SubjectNumericRace                   8.388519\n",
       "DODRace                              1.513826\n",
       "Age                                 30.015401\n",
       "Heightin                            70.017501\n",
       "Length: 97, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean = X_train.mean()\n",
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train / x_mean\n",
    "X_test_normalized = X_test/x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Applying a threshold of 0.003 removes approximately 50% of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(X_train_normalized.var() > 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(X_train_normalized.var() > 0.003)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "vt = VarianceThreshold(threshold=0.003)\n",
    "vt.fit_transform(X_train_normalized)\n",
    "\n",
    "mask = vt.get_support()\n",
    "mask # mask tells which column to retain or remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_normalized.loc[:, mask]\n",
    "X_test_final = X_test_normalized.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt.get_feature_names_out() #show the retained features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.shape # Ensure that the number of columns is half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train_final, y_train)\n",
    "print(f\"Training Score: {model.score(X_train_final, y_train)}\")\n",
    "print(f\"Test Score: {model.score(X_test_final, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: \n",
    "1. Time taken for model training is reduced by more than half.\n",
    "2. Model accuracy is not at all affected on both train and test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Identify quasi-constant features with Feature Engine\n",
    "\n",
    "1. !pip install feature-engine\n",
    "2. Feature-engine is an open source Python library with the most exhaustive battery of transformers to engineer features for use in machine learning models. Feature-engine simplifies and streamlines the implementation of and end-to-end feature engineering pipeline, by allowing the selection of feature subsets within its transformers, and returning dataframes for easy data exploration. Feature-engine’s transformers preserve Scikit-learn functionality with the methods fit() and transform() to learn parameters from and then transform data\n",
    "3. https://feature-engine.trainindata.com/en/latest/\n",
    "4. https://feature-engine.trainindata.com/en/latest/api_doc/index.html\n",
    "5. https://feature-engine.trainindata.com/en/latest/user_guide/selection/DropConstantFeatures.html\n",
    "6. DropConstantFeatures takes a tolerance level. E.g. tol=.7 to remove features that show the same value in more than 70% of the observations\n",
    "7. Here is a good executive summary of available product features: https://trainindata.medium.com/feature-engine-a-new-open-source-python-package-for-feature-engineering-29a0ab88ea7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.datasets import load_titanic\n",
    "from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "X, y = load_titanic(return_X_y_frame=True, handle_missing=True,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape # 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['embarked'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** More than 70% of values in the embarked feature are same viz S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = DropConstantFeatures(tol=0.7)\n",
    "transformer.fit(X_train)\n",
    "transformer.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vars = transformer.transform(X_train)\n",
    "X_test_vars = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vars.shape # 4 features dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.get_support() #this is similar to sklearn VarianceThreshold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Highly correlated features\n",
    "\n",
    "While high correlation between feature and target is good, high correlation between features is not good\n",
    "\n",
    "##### 3.1 Visualize heatmap\n",
    "\n",
    "**Warning**\n",
    "1. Correlation is a linear measure. \n",
    "2. There can be non linear relation. That will not be measured by pearson's correlation \n",
    "3. Use mutual information to measure that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df_housing[\"target\"] = housing.target\n",
    "df_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the size of the heatmap.\n",
    "plt.figure(figsize=(16, 6))\n",
    "# Store heatmap object in a variable to easily access it when \n",
    "# you want to include more features (such as title).\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and \n",
    "# set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(df_housing.corr(), vmin=-1, vmax=1, annot=True)\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: AveRooms and AveBedrooms are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_housing[\"AveRooms\"], df_housing[\"AveBedrms\"], alpha=0.3, color=\"purple\")\n",
    "plt.xlabel(\"var_8\")\n",
    "plt.ylabel(\"var_6\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diverging color palette that has markedly different colors at the two ends of the value-range with a pale, almost colorless midpoint, works much better with correlation heatmaps than the default colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "heatmap = sns.heatmap(df_housing.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);\n",
    "\n",
    "#plt.savefig('heatmap.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing target column with triu-1 lets us focus only on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# define the mask to set the values in the upper triangle to True\n",
    "mask = np.triu(np.ones_like(df_housing.corr(), dtype=np.bool))\n",
    "heatmap = sns.heatmap(df_housing.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Spearman correlation\n",
    "\n",
    "In this case Spearman correlation does not deviate much from pearson for Latitude and Longitude. However Spearmzn correlation between AveRooms and AvgBedrooms very less. Correpsonding pearson correlation was high. This indicates either one of those two columns contain outliers or some other reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# define the mask to set the values in the upper triangle to True\n",
    "mask = np.triu(np.ones_like(df_housing.corr(), dtype=np.bool))\n",
    "heatmap = sns.heatmap(df_housing.corr(method=\"spearman\"), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Using Feature Engine to drop correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of features: {df_housing.iloc[:,:-1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "\n",
    "sel = DropCorrelatedFeatures(method=\"pearson\", threshold=0.8)\n",
    "sel.fit(df_housing.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_corr = sel.transform(df_housing.iloc[:,:-1]) # 2 columns are dropped \n",
    "X_no_corr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Remove correlated features and retain the best correlated feature with target\n",
    "\n",
    "1. Removing correlated features in previous section removed all but one correlated feature.\n",
    "2. But there is no guarantee that the retained feature is the one that has best correlation with target variable\n",
    "3. In a given dataset, we can find groups of features that are correlated among themselves or to a given feature. From every one of these groups, we can retain the feature that brings most value to the\n",
    "predictive model and remove the rest\n",
    "4. FeatureEngine provides a class called SmartCorrelatedSelection for this purpose. \n",
    "5. SmartCorrelatedSelection identifies features with a correlation coefficient higher configured value, then retain the feature with the highest importance from each group of correlated variables.\n",
    "6. In this sense it is a wrapper method, but the goal it achieves is similar to Filter method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_housing.iloc[:,:-1]\n",
    "y = df_housing.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "sel = SmartCorrelatedSelection(method=\"pearson\", threshold=0.8, \n",
    "                               selection_method=\"model_performance\",\n",
    "                               estimator=RandomForestRegressor(n_estimators=5, random_state=10),\n",
    "                               scoring=\"r2\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uncorrel = sel.transform(X_train)\n",
    "X_test_uncorrel = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uncorrel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter methods\n",
    "\n",
    "1. All filter methods are supervised.\n",
    "2. Implemented froms scratch and with SelectKBest\n",
    "\n",
    "##### 4.1 Data preprocessing of Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic=sns.load_dataset('titanic')\n",
    "\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = titanic[0]\n",
    "df_titanic['survived'] = titanic[1] \n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique values for feature cabin {df_titanic['cabin'].nunique()}\")\n",
    "print(f\"Unique values for feature body {df_titanic['body'].nunique()}\")\n",
    "print(f\"Unique values for feature boat {df_titanic['boat'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['survived'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.drop(columns=[\"name\", \"ticket\", \"cabin\", \"body\", \"home.dest\", \"boat\"], inplace=True)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = df_titanic[\"embarked\"].isna()\n",
    "np.where(df_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.drop(np.where(df_titanic[\"embarked\"].isna())[0], inplace=True)\n",
    "df_titanic.drop(np.where(df_titanic[\"fare\"].isna())[0], inplace=True)\n",
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_titanic.iloc[:,:-1:]\n",
    "y = df_titanic.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl_encoder = LabelEncoder()\n",
    "sex_train_encoded = lbl_encoder.fit_transform(X_train[\"sex\"])\n",
    "sex_test_encoded = lbl_encoder.transform(X_test[\"sex\"])\n",
    "\n",
    "lbl_encoder2 = LabelEncoder()\n",
    "embark_train_encoded = lbl_encoder.fit_transform(X_train[\"embarked\"])\n",
    "embark_test_encoded = lbl_encoder.transform(X_test[\"embarked\"])\n",
    "\n",
    "tgt_encoder = LabelEncoder()\n",
    "y_train_encoded = tgt_encoder.fit_transform(y_train)\n",
    "y_test_encoded = tgt_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.hstack( \n",
    "    (X_train.iloc[:,0:1].to_numpy(), sex_train_encoded.reshape(-1,1), \n",
    "     X_train.iloc[:,2:6].to_numpy(), embark_train_encoded.reshape(-1,1)))\n",
    "X_test_new = np.hstack(\n",
    "    (X_test.iloc[:,0:1].to_numpy(), sex_test_encoded.reshape(-1,1), \n",
    "     X_test.iloc[:,2:6].to_numpy(), embark_test_encoded.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=7, weights='uniform', metric='nan_euclidean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_new)\n",
    "X_train_imputed[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Finding feature importance with mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.contingency import crosstab\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1 direct\n",
    "mi = mutual_info_score(y_train, X_train['sex'])\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2 get crosstab first and then mi\n",
    "c = crosstab(y_train, X_train['sex'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_score(labels_true=None, labels_pred=None, contingency = c[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** There is mutual information between sex and survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Find mutual information in the most direct manner between all features and categorical target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mi_score = mutual_info_classif(X_train_imputed, y_train, n_neighbors=10, random_state=22)\n",
    "sorted_idx = np.argsort(mi_score)\n",
    "mi_scoredf = pd.DataFrame(\n",
    "    mi_score[sorted_idx[::-1]], \n",
    "    index=X_train.columns[sorted_idx[::-1]], \n",
    "    columns=['mi_score'])\n",
    "plt.barh(\n",
    "    X_train.columns[sorted_idx], \n",
    "    mi_score[sorted_idx])\n",
    "plt.xlabel(\"Mutual Information Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Mutual Information between numerical/categorical feature and a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "#fare and age\n",
    "mutual_info_regression(X_train_imputed[:,5].reshape(-1,1), \n",
    "                       X_train_imputed[:,2], discrete_features=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5 Find feature importance with chi square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.crosstab(y_train, X_train['sex'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2_contingency(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_ls = []\n",
    "for feature in X_train.columns: # create contingency table\n",
    "    c = pd.crosstab(y_train, X_train[feature])\n",
    "    # chi-square test\n",
    "    p_value = chi2_contingency(c)[1]\n",
    "    chi_ls.append(p_value)\n",
    "\n",
    "pd.Series(chi_ls, index=X_train.columns).sort_values(ascending=True).plot.bar(rot=45)\n",
    "plt.ylabel(\"p value\")\n",
    "plt.title(\"Feature importance based on chi-square test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.Series(chi_ls, index=X_train.columns).sort_values(ascending=True)[0:3].index\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6 Feature Selection with SelectKBest and scoring = chisquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(score_func=chi2, k=4)\n",
    "fit = kbest.fit(X_train_imputed, y_train)\n",
    "fit.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.columns[[0,1,5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6 Feature Selection with SelectKBest and scoring = mutual_info_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "fit = kbest.fit(X_train_imputed, y_train)\n",
    "fit.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest.get_feature_names_out() #notice the difference between this and chisquared based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Apply chisquared to wine dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X,y=load_wine(return_X_y=True)\n",
    "\n",
    "# k = 4 tells four top features to be selected\n",
    "# Score function Chi2 tells the feature to be selected using Chi Square\n",
    "wine_kbest = SelectKBest(score_func=chi2, k=4)\n",
    "_ = wine_kbest.fit(X, y)\n",
    "\n",
    "wine_kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_kbest.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Selection with Lasso Regression\n",
    "\n",
    "1. For Lasso with Linear Regression, see linear_regression_reference.ipynb\n",
    "2. Below is code for logistic regression with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/'\n",
    "                      'ml/machine-learning-databases/wine/wine.data',\n",
    "                      header=None)\n",
    "\n",
    "# if the Wine dataset is temporarily unavailable from the\n",
    "# UCI machine learning repository, un-comment the following line\n",
    "# of code to load the dataset from a local path:\n",
    "\n",
    "# df_wine = pd.read_csv('wine.data', header=None)\n",
    "\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                   'Proline']\n",
    "\n",
    "print('Class labels', np.unique(df_wine['Class label']))\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', multi_class='ovr')\n",
    "# Note that C=1.0 is the default. You can increase\n",
    "# or decrease it to make the regulariztion effect\n",
    "# stronger or weaker, respectively.\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_[lr.coef_!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "    \n",
    "colors = ['blue', 'green', 'red', 'cyan', \n",
    "          'magenta', 'yellow', 'black', \n",
    "          'pink', 'lightgreen', 'lightblue', \n",
    "          'gray', 'indigo', 'orange']\n",
    "\n",
    "weights, params = [], []\n",
    "for c in np.arange(-4., 6.):\n",
    "    lr = LogisticRegression(penalty='l1', C=10.**c, solver='liblinear', \n",
    "                            multi_class='ovr', random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)\n",
    "\n",
    "weights = np.array(weights)\n",
    "\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column],\n",
    "             label=df_wine.columns[column + 1],\n",
    "             color=color)\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('Weight coefficient')\n",
    "plt.xlabel('C (inverse regularization strength)')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center', \n",
    "          bbox_to_anchor=(1.38, 1.03),\n",
    "          ncol=1, fancybox=True)\n",
    "plt.savefig('lasso-path.pdf', dpi=300, \n",
    "            bbox_inches='tight', pad_inches=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Selection with Feature Importance in Decision Tree\n",
    "\n",
    "1. DIY\n",
    "2. Using sklearn\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y = make_classification(n_samples=5, n_classes=2,\n",
    "                               n_features=2, n_informative=2, n_redundant=0,\n",
    "                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Calculate feature importance using the formula**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate feature importance using sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. How Feature Importance is calculated in Random Forest\n",
    "\n",
    "Run the relevant section from bagging_ensemble_randomforest.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Problems with Tree based default feature importance\n",
    "\n",
    "1. Inflated feature importance for numerical feature\n",
    "2. Inflated feature importance for categorical feature with high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "df_titanic = titanic[0]\n",
    "df_titanic['survived'] = titanic[1] \n",
    "df_titanic.drop(columns=[\"name\", \"ticket\", \"cabin\", \"body\", \"home.dest\", \"boat\"], inplace=True)\n",
    "df_titanic.drop(np.where(df_titanic[\"embarked\"].isna())[0], inplace=True)\n",
    "df_titanic.drop(np.where(df_titanic[\"fare\"].isna())[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_titanic.iloc[:,:-1:]\n",
    "y = df_titanic.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=42)\n",
    "X[\"random_cat\"] = rng.randint(3, size=X.shape[0])\n",
    "X[\"random_num\"] = rng.randn(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "lbl_encoder = LabelEncoder()\n",
    "sex_train_encoded = lbl_encoder.fit_transform(X_train[\"sex\"])\n",
    "sex_test_encoded = lbl_encoder.transform(X_test[\"sex\"])\n",
    "\n",
    "lbl_encoder2 = LabelEncoder()\n",
    "embark_train_encoded = lbl_encoder.fit_transform(X_train[\"embarked\"])\n",
    "embark_test_encoded = lbl_encoder.transform(X_test[\"embarked\"])\n",
    "\n",
    "tgt_encoder = LabelEncoder()\n",
    "y_train_encoded = tgt_encoder.fit_transform(y_train)\n",
    "y_test_encoded = tgt_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.hstack( \n",
    "    (X_train.iloc[:,0:1].to_numpy(), sex_train_encoded.reshape(-1,1), \n",
    "     X_train.iloc[:,2:6].to_numpy(), embark_train_encoded.reshape(-1,1)))\n",
    "X_test_new = np.hstack(\n",
    "    (X_test.iloc[:,0:1].to_numpy(), sex_test_encoded.reshape(-1,1), \n",
    "     X_test.iloc[:,2:6].to_numpy(), embark_test_encoded.reshape(-1,1)))\n",
    "\t \n",
    "\t \n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=7, weights='uniform', metric='nan_euclidean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_new)\n",
    "X_test_imputed = imputer.fit_transform(X_test_new)\n",
    "X_train_imputed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed = np.hstack( (X_train_imputed, X_train.loc[:, [\"random_cat\", \"random_num\"]].to_numpy()))\n",
    "X_test_imputed = np.hstack( (X_test_imputed, X_test.loc[:, [\"random_cat\", \"random_num\"]].to_numpy()))\n",
    "\n",
    "X_train_imputed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "         n_estimators=100,\n",
    "         n_jobs=-1,\n",
    "         min_samples_leaf = 1,\n",
    "         oob_score=True,\n",
    "         random_state = 42)\n",
    "rf.fit(X_train_imputed, y_train)\n",
    "\n",
    "print(f\"RF train accuracy: {rf.score(X_train_imputed, y_train):.3f}\")\n",
    "print(f\"RF test accuracy: {rf.score(X_test_imputed, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "feat_importances = pd.Series(rf.feature_importances_, index = X_train.columns).sort_values(ascending = True)\n",
    "feat_importances.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Permutation based feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#calculate permutation importance for test data \n",
    "result_test = permutation_importance(\n",
    "    rf, X_test_imputed, y_test, n_repeats=20, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx_test = result_test.importances_mean.argsort()\n",
    "importances_test = pd.DataFrame(\n",
    "    result_test.importances[sorted_importances_idx_test].T,\n",
    "    columns=X.columns[sorted_importances_idx_test],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate permutation importance for training data \n",
    "result_train = permutation_importance(\n",
    "    rf, X_train_imputed, y_train, n_repeats=20, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx_train = result_train.importances_mean.argsort()\n",
    "importances_train = pd.DataFrame(\n",
    "    result_train.importances[sorted_importances_idx_train].T,\n",
    "    columns=X.columns[sorted_importances_idx_train],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "importances_test.plot.box(vert=False, whis=10, ax = axs[0])\n",
    "axs[0].set_title(\"Permutation Importances (test set)\")\n",
    "axs[0].axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "axs[0].set_xlabel(\"Decrease in accuracy score\")\n",
    "axs[0].figure.tight_layout()\n",
    "\n",
    "importances_train.plot.box(vert=False, whis=10, ax = axs[1])\n",
    "axs[1].set_title(\"Permutation Importances (train set)\")\n",
    "axs[1].axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "axs[1].set_xlabel(\"Decrease in accuracy score\")\n",
    "axs[1].figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.2 Drop Column variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "def dropcol_importances(rf, X_train, y_train):\n",
    "    rf_ = clone(rf)\n",
    "    rf_.random_state = 42\n",
    "    rf_.fit(X_train, y_train)\n",
    "    \n",
    "    #use out of bag error as performance measurement\n",
    "    baseline = rf_.oob_score_\n",
    "    imp = []\n",
    "    for col in X_train.columns:\n",
    "        X = X_train.drop(col, axis=1)\n",
    "        rf_ = clone(rf)\n",
    "        rf_.random_state = 42\n",
    "        rf_.fit(X, y_train)\n",
    "        o = rf_.oob_score_\n",
    "        imp.append(baseline - o)\n",
    "    imp = np.array(imp)\n",
    "    I = pd.DataFrame(\n",
    "            data={'Feature':X_train.columns,\n",
    "                  'Importance':imp})\n",
    "    I = I.set_index('Feature')\n",
    "    I = I.sort_values('Importance', ascending=True)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_train = pd.DataFrame(data=X_train_imputed, columns=X_train.columns)\n",
    "imp = dropcol_importances(rf, df_titanic_train, y_train)\n",
    "imp.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state=123)\n",
    "\n",
    "rfe = RFE(estimator=lr, n_features_to_select=5, step=1)\n",
    "rfe.fit(X_train_imputed, y_train)\n",
    "\n",
    "X_train_sub = rfe.transform(X_train_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which features got selected?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. RFE as part of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "pipe = make_pipeline(RFE(estimator=lr, step=1),\n",
    "                     KNeighborsClassifier())\n",
    "\n",
    "\n",
    "parameters = {'rfe__n_features_to_select': range(1, 13), \n",
    "              'kneighborsclassifier__n_neighbors': range(1, 10) }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=10, n_jobs=-1)\n",
    "grid.fit(X_train_imputed, y_train)\n",
    "\n",
    "print('Best params:', grid.best_params_)\n",
    "print('Best accuracy:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.score(X_test_imputed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate implementation to compare performance\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_imputed, y_train)\n",
    "knn.score(X_test_imputed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFE add-on with Yellow bricks**\n",
    "\n",
    "Not working as of now due to dataset issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# from yellowbrick.model_selection import rfecv\n",
    "# from yellowbrick.datasets import load_bikeshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load classification dataset\n",
    "# X, y = load_bikeshare()\n",
    "\n",
    "# cv = StratifiedKFold(5)\n",
    "# visualizer = rfecv(RandomForestClassifier(), X=X, y=y, cv=cv, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
